{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR training on patch level pooled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "np.random.seed(761)\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"figure\", facecolor=\"white\")\n",
    "from matplotlib import lines\n",
    "import random\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(path):\n",
    "    labels = pd.read_csv(path, sep='\\t')\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(train):\n",
    "    # set class weights to deal with the unbalanced nature of the data\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                      np.unique(train),\n",
    "                                                      train)\n",
    "\n",
    "    class_weights = {i: j for i, j in zip(range(2), class_weights)}\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_lr_pools(features, labels, do_pca=False, num_pcs=50, splits=10,\n",
    "                    seed=None, return_list= False, verbose=False):\n",
    "        \n",
    "    aucs = []\n",
    "    for seed_index, split in enumerate(range(splits)):\n",
    "        # test train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                            labels,\n",
    "                                                            train_size=0.8,\n",
    "                                                            random_state=seed[seed_index])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        if do_pca:\n",
    "            pca = PCA()\n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_train = X_train[:, :num_pcs]\n",
    "            X_test = pca.transform(X_test)\n",
    "            X_test = X_test[:, :num_pcs]\n",
    "        \n",
    "        if do_pca:\n",
    "            # better safe than sorry\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        \n",
    "        class_weights = get_weights(y_train)\n",
    "        clf = LR(penalty='l2', class_weight='balanced', C=0.0001)    \n",
    "        clf = clf.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate performance\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test, probs[:,1])\n",
    "        if verbose:\n",
    "            print('Accuracy on Test Data:  {0}'.format(clf.score(X_test, y_test)))\n",
    "            print('AUC:  {0}\\n'.format(auc))\n",
    "        aucs.append(auc)\n",
    "             \n",
    "    return aucs if return_list else sum(aucs)/len(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def mean_rocs(features, labels, num_pcs=50, splits=10,\n",
    "                   seed=None, return_list= False, verbose=False):\n",
    "    # https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "        \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for seed_index, split in enumerate(range(splits)):\n",
    "        # test train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                            labels,\n",
    "                                                            train_size=0.8,\n",
    "                                                            random_state=seed[seed_index])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        pca = PCA()\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_train = X_train[:, :num_pcs]\n",
    "        X_test = pca.transform(X_test)\n",
    "        X_test = X_test[:, :num_pcs]\n",
    "        \n",
    "        # better safe than sorry\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        class_weights = get_weights(y_train)\n",
    "        clf = LR(penalty='l2', class_weight='balanced', C=0.0001)    \n",
    "        probs = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probs[:, 1])\n",
    "        auc = roc_auc_score(y_test, probs[:,1])\n",
    "        aucs.append(auc)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "            \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_aucs = round(sum(aucs)/len(aucs), 2)\n",
    "        \n",
    "    return (mean_fpr, mean_tpr, mean_aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Determine Optimal Number of PCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a range of pcs to evaluate\n",
    "pc_range = np.arange(10, 301, 10)\n",
    "\n",
    "# we will do 10 splits\n",
    "random_splits = np.random.choice(1000, 10, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_labels('../images.paths.labels.binary.tsv')\n",
    "samples = meta['sample'].unique()\n",
    "label_dict = {i:meta[meta['sample'] == i].iloc[0]['tmb_label'] for i in samples}\n",
    "\n",
    "# three different types of pooling:  avg, max, and p_norm\n",
    "avg_features = pd.read_csv('../features/tmb.inceptionv3.avg.pooled.tsv', sep='\\t').transpose()\n",
    "max_features = pd.read_csv('../features/tmb.inceptionv3.max.pooled.tsv', sep='\\t').transpose()\n",
    "pnorm_features = pd.read_csv('../features/tmb.inceptionv3.p_norm.pooled.tsv', sep='\\t').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg aucs\n",
    "auc_avg = []; auc_max = []; auc_pnorm = []\n",
    "for pcs in pc_range:\n",
    "    labels = [label_dict[i] for i in avg_features.index.tolist()]\n",
    "    auc_avg.append(train_lr_pools(avg_features,\n",
    "                                  labels,\n",
    "                                  do_pca=True,\n",
    "                                  num_pcs=pcs,\n",
    "                                  splits=len(random_splits),\n",
    "                                  seed=random_splits))\n",
    "    \n",
    "    labels = [label_dict[i] for i in max_features.index.tolist()]\n",
    "    auc_max.append(train_lr_pools(max_features,\n",
    "                                  labels,\n",
    "                                  do_pca=True,\n",
    "                                  num_pcs=pcs, \n",
    "                                  splits=len(random_splits), \n",
    "                                  seed=random_splits))\n",
    "\n",
    "    labels = [label_dict[i] for i in pnorm_features.index.tolist()]\n",
    "    auc_pnorm.append(train_lr_pools(pnorm_features,\n",
    "                                    labels, do_pca=True,\n",
    "                                    num_pcs=pcs, \n",
    "                                    splits=len(random_splits), \n",
    "                                    seed=random_splits))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(pc_range, auc_avg)\n",
    "plt.plot(pc_range, auc_avg, label='Average Pooling')\n",
    "\n",
    "plt.scatter(pc_range, auc_max)\n",
    "plt.plot(pc_range, auc_max, label='Max Pooling')\n",
    "\n",
    "plt.scatter(pc_range, auc_pnorm)\n",
    "plt.plot(pc_range, auc_pnorm, label='P-norm Pooling')\n",
    "\n",
    "plt.xlabel('Number of Principal Components', fontsize=24)\n",
    "plt.ylabel('AUC', fontsize=24)\n",
    "\n",
    "plt.xlim([0, max(pc_range)])\n",
    "plt.xticks(fontsize=22)\n",
    "plt.ylim([0.4, 1])\n",
    "plt.yticks(np.arange(0.4,1.001, 0.1), fontsize=22)\n",
    "\n",
    "plt.legend(fontsize=24)\n",
    "#plt.title('Average AUC, TMB', fontsize=22)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_labels('../images.paths.labels.immune.binary.tsv')\n",
    "samples = meta['sample'].unique()\n",
    "label_dict = {i:meta[meta['sample'] == i].iloc[0]['immune_sig'] for i in samples}\n",
    "\n",
    "# three different types of pooling:  avg, max, and p_norm\n",
    "avg_features = pd.read_csv('../features/immune.inceptionv3.avg.pooled.tsv', sep='\\t').transpose()\n",
    "max_features = pd.read_csv('../features/immune.inceptionv3.max.pooled.tsv', sep='\\t').transpose()\n",
    "pnorm_features = pd.read_csv('../features/immune.inceptionv3.p_norm.pooled.tsv', sep='\\t').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg aucs\n",
    "auc_avg = []; auc_max = []; auc_pnorm = []\n",
    "for pcs in pc_range:\n",
    "    labels = [label_dict[i] for i in avg_features.index.tolist()]\n",
    "    auc_avg.append(train_lr_pools(avg_features,\n",
    "                                  labels,\n",
    "                                  do_pca=True, \n",
    "                                  num_pcs=pcs, \n",
    "                                  splits=10,\n",
    "                                  seed=random_splits))\n",
    "    \n",
    "    labels = [label_dict[i] for i in max_features.index.tolist()]\n",
    "    auc_max.append(train_lr_pools(max_features,\n",
    "                                  labels,\n",
    "                                  do_pca=True,\n",
    "                                  num_pcs=pcs,\n",
    "                                  splits=10,\n",
    "                                  seed=random_splits))\n",
    "    \n",
    "    labels = [label_dict[i] for i in pnorm_features.index.tolist()]\n",
    "    auc_pnorm.append(train_lr_pools(pnorm_features,\n",
    "                                    labels, \n",
    "                                    do_pca=True, \n",
    "                                    num_pcs=pcs, \n",
    "                                    splits=10, \n",
    "                                    seed=random_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(pc_range, auc_avg)\n",
    "plt.plot(pc_range, auc_avg, label='Average Pooling')\n",
    "\n",
    "plt.scatter(pc_range, auc_max)\n",
    "plt.plot(pc_range, auc_max, label='Max Pooling')\n",
    "\n",
    "plt.scatter(pc_range, auc_pnorm)\n",
    "plt.plot(pc_range, auc_pnorm, label='P-norm Pooling')\n",
    "\n",
    "plt.xlabel('Number of Principal Components', fontsize=24)\n",
    "plt.ylabel('AUC', fontsize=24)\n",
    "\n",
    "plt.xlim([0, max(pc_range)])\n",
    "plt.xticks(fontsize=22)\n",
    "plt.ylim([0.4, 1])\n",
    "plt.yticks(np.arange(0.4,1.001, 0.1), fontsize=22)\n",
    "\n",
    "plt.legend(fontsize=24)\n",
    "#plt.title('Average AUC, Immune Signature', fontsize=22)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ROC Curves,  boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 PCs is best for both classification tasks\n",
    "# MAX pooling is best for TMB and average is best for immune signature\n",
    "best_pcs = 30\n",
    "\n",
    "meta = load_labels('../images.paths.labels.binary.tsv')\n",
    "samples = meta['sample'].unique()\n",
    "label_dict_tmb = {i:meta[meta['sample'] == i].iloc[0]['tmb_label'] for i in samples}\n",
    "tmb_avg = pd.read_csv('../features/tmb.inceptionv3.avg.pooled.tsv', sep='\\t').transpose()\n",
    "tmb_max = pd.read_csv('../features/tmb.inceptionv3.max.pooled.tsv', sep='\\t').transpose()\n",
    "tmb_pnorm = pd.read_csv('../features/tmb.inceptionv3.p_norm.pooled.tsv', sep='\\t').transpose()\n",
    "\n",
    "meta = load_labels('../images.paths.labels.immune.binary.tsv')\n",
    "samples = meta['sample'].unique()\n",
    "label_dict_immune = {i:meta[meta['sample'] == i].iloc[0]['immune_sig'] for i in samples}\n",
    "immune_avg = pd.read_csv('../features/immune.inceptionv3.avg.pooled.tsv', sep='\\t').transpose()\n",
    "immune_max = pd.read_csv('../features/immune.inceptionv3.max.pooled.tsv', sep='\\t').transpose()\n",
    "immune_pnorm = pd.read_csv('../features/immune.inceptionv3.p_norm.pooled.tsv', sep='\\t').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a boxplot of the AUC across multiple splits\n",
    "aucs_all = []\n",
    "for features in [tmb_avg, tmb_max, tmb_pnorm]:\n",
    "    labels = [label_dict_tmb[i] for i in features.index.tolist()]\n",
    "    aucs_all.append(train_lr_pools(features,\n",
    "                              labels,\n",
    "                              do_pca=True,\n",
    "                              num_pcs=best_pcs,\n",
    "                              splits=10,\n",
    "                              seed=random_splits,\n",
    "                              return_list=True))\n",
    "\n",
    "immune_aucs = []\n",
    "for features in [immune_avg, immune_max, immune_pnorm]:\n",
    "    labels = [label_dict_immune[i] for i in features.index.tolist()]\n",
    "    aucs_all.append(train_lr_pools(features,\n",
    "                              labels,\n",
    "                              do_pca=True,\n",
    "                              num_pcs=best_pcs,\n",
    "                              splits=10,\n",
    "                              seed=random_splits,\n",
    "                              return_list=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.boxplot(aucs_all, widths=(0.1)*len(aucs_all))\n",
    "\n",
    "for i in range(len(aucs_all)):\n",
    "    y = aucs_all[i]\n",
    "    x = np.random.normal(i+1, 0.03, size=len(y))\n",
    "    plt.plot(x, y, 'b.', alpha=0.5, markersize=12)\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(range(1, 7), ['Average', 'Max', 'P-norm']*2, fontsize=22)\n",
    "plt.yticks(np.arange(0,1.001, 0.1), fontsize=22)\n",
    "plt.ylabel('AUC', fontsize=24)\n",
    "#plt.title('AUC Distribution\\n30 PCs, 10 train/test splits', fontsize=22)\n",
    "\n",
    "plt.annotate('', xy=(0.05, -0.1), xycoords='axes fraction', xytext=(0.45, -0.1), \n",
    "            arrowprops=dict(arrowstyle=\"-\", color='black'))\n",
    "\n",
    "plt.annotate('', xy=(0.55, -0.1), xycoords='axes fraction', xytext=(0.95, -0.1), \n",
    "            arrowprops=dict(arrowstyle=\"-\", color='black'))\n",
    "\n",
    "plt.text(1.78,-.17,'TMB', fontsize=24)\n",
    "plt.text(4,-.17,'Immune Signature', fontsize=24)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate a ROC curve\n",
    "labels = [label_dict_tmb[i] for i in tmb_max.index.tolist()]\n",
    "tmb_fpr, tmb_tpr, tmb_aucs = mean_rocs(tmb_max, labels, num_pcs=best_pcs, splits=10, seed=random_splits)\n",
    "\n",
    "labels = [label_dict_immune[i] for i in immune_avg.index.tolist()]\n",
    "immune_fpr, immune_tpr, immune_aucs = mean_rocs(immune_avg, labels, num_pcs=best_pcs, splits=10, seed=random_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(tmb_fpr, tmb_tpr, label='TMB\\nMax Pooling\\nAUC - {0}'.format(tmb_aucs), color='dodgerblue', linewidth=3)\n",
    "plt.plot(immune_fpr, immune_tpr, label='Immune Signature\\nAvgerage Pooling\\nAUC - {0}'.format(immune_aucs), color='salmon', linewidth=3)\n",
    "\n",
    "plt.xticks(np.arange(0,1.001,0.1), fontsize=22)\n",
    "plt.yticks(np.arange(0,1.001,0.1), fontsize=22)\n",
    "plt.legend(fontsize=24)\n",
    "plt.ylabel('Sensitivity', fontsize=24)\n",
    "plt.xlabel('1 - Specificity', fontsize=24)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "\n",
    "#plt.title('TMB Max Pooling\\nImmune Signature Average Pooling\\nROC', fontsize=22)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
